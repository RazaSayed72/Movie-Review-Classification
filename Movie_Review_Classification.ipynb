{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bbfc203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\razas\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd8c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\razas\\Downloads\\TechnoHacks Internship\\Technohack Machine Learning\\Movie review classification\\labeledTrainData.tsv\\labeledTrainData.tsv\"\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", quoting=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be917bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>\"3453_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It seems like more consideration has gone int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>\"5064_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I don't believe they made this film. Complete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>\"10905_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Guy is a loser. Can't get girls, needs to bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>\"10194_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"This 30 minute documentary Buñuel made in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>\"8478_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I saw this movie as a child and it broke my h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  sentiment                                             review\n",
       "0       \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1       \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2       \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3       \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4       \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...\n",
       "...          ...        ...                                                ...\n",
       "24995   \"3453_3\"          0  \"It seems like more consideration has gone int...\n",
       "24996   \"5064_1\"          0  \"I don't believe they made this film. Complete...\n",
       "24997  \"10905_3\"          0  \"Guy is a loser. Can't get girls, needs to bui...\n",
       "24998  \"10194_3\"          0  \"This 30 minute documentary Buñuel made in the...\n",
       "24999   \"8478_8\"          1  \"I saw this movie as a child and it broke my h...\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38bc27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"movie_reviews.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "535669c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\razas\\Downloads\\TechnoHacks Internship\\Technohack Machine Learning\\Movie review classification\\unlabeledTrainData.tsv\\unlabeledTrainData.tsv\"\n",
    "df2 = pd.read_csv(file_path, sep=\"\\t\", quoting=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "967e8c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"9999_0\"</td>\n",
       "      <td>\"Watching Time Chasers, it obvious that it was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"45057_0\"</td>\n",
       "      <td>\"I saw this film about 20 years ago and rememb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"15561_0\"</td>\n",
       "      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7161_0\"</td>\n",
       "      <td>\"I went to see this film with a great deal of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"43971_0\"</td>\n",
       "      <td>\"Yes, I agree with everyone on this site this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>\"18984_0\"</td>\n",
       "      <td>\"The original Man Eater by Joe D'Amato is some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>\"16433_0\"</td>\n",
       "      <td>\"When Home Box Office was in it's early days m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>\"16006_0\"</td>\n",
       "      <td>\"Griffin Dunne was born into a cultural family...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>\"40155_0\"</td>\n",
       "      <td>\"Not a bad story, but the low budget rears its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>\"35270_0\"</td>\n",
       "      <td>\"This not-very-good mummy-alien flick does fea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                             review\n",
       "0       \"9999_0\"  \"Watching Time Chasers, it obvious that it was...\n",
       "1      \"45057_0\"  \"I saw this film about 20 years ago and rememb...\n",
       "2      \"15561_0\"  \"Minor Spoilers<br /><br />In New York, Joan B...\n",
       "3       \"7161_0\"  \"I went to see this film with a great deal of ...\n",
       "4      \"43971_0\"  \"Yes, I agree with everyone on this site this ...\n",
       "...          ...                                                ...\n",
       "49995  \"18984_0\"  \"The original Man Eater by Joe D'Amato is some...\n",
       "49996  \"16433_0\"  \"When Home Box Office was in it's early days m...\n",
       "49997  \"16006_0\"  \"Griffin Dunne was born into a cultural family...\n",
       "49998  \"40155_0\"  \"Not a bad story, but the low budget rears its...\n",
       "49999  \"35270_0\"  \"This not-very-good mummy-alien flick does fea...\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9597690",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"movie_reviews_unclass.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6f1b3",
   "metadata": {},
   "source": [
    "#    PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4130c900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\razas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\razas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\razas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\razas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')            # Tokenization\n",
    "nltk.download('stopwords')        # Stopwords\n",
    "nltk.download('wordnet')          # Lemmatization\n",
    "nltk.download('omw-1.4')          # WordNet lemmatizer dependency\n",
    "\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        text = re.sub(r'<.*?>', ' ', text)  # Remove HTML tags\n",
    "        text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)  # Remove punctuation\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "        \n",
    "        tokens = nltk.word_tokenize(text)  # Tokenize\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [word for word in tokens if word not in stop_words]  # Remove stop words\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatize\n",
    "        \n",
    "        return \" \".join(tokens)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Apply preprocessing to the 'review' column\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4a67061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Target Variable\n",
    "Y = df['sentiment']  # assuming 0 = negative, 1 = positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45c5de7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sentiment', 'review', 'cleaned_review'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56660a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b89aeee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#split the data into test and train \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f18ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.84\n",
      "Precision: 0.84\n",
      "Recall: 0.84\n",
      "F1-Score: 0.84\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84      3701\n",
      "           1       0.85      0.83      0.84      3799\n",
      "\n",
      "    accuracy                           0.84      7500\n",
      "   macro avg       0.84      0.84      0.84      7500\n",
      "weighted avg       0.84      0.84      0.84      7500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3151  550]\n",
      " [ 661 3138]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "Y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')  # use 'macro' or 'binary' as per need\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Random Forest Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21215f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "Accuracy: 0.88\n",
      "Precision: 0.88\n",
      "Recall: 0.88\n",
      "F1-Score: 0.88\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      3701\n",
      "           1       0.88      0.90      0.89      3799\n",
      "\n",
      "    accuracy                           0.88      7500\n",
      "   macro avg       0.88      0.88      0.88      7500\n",
      "weighted avg       0.88      0.88      0.88      7500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3228  473]\n",
      " [ 395 3404]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "Y_pred = log_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81181cf7",
   "metadata": {},
   "source": [
    "# logistic regression is the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b1090dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Linear SVC ===\n",
      "Accuracy: 0.88\n",
      "Precision: 0.88\n",
      "Recall: 0.88\n",
      "F1-Score: 0.88\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87      3701\n",
      "           1       0.87      0.88      0.88      3799\n",
      "\n",
      "    accuracy                           0.88      7500\n",
      "   macro avg       0.88      0.88      0.88      7500\n",
      "weighted avg       0.88      0.88      0.88      7500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3219  482]\n",
      " [ 447 3352]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train the Linear Support Vector Classifier\n",
    "svc_model = LinearSVC(random_state=42)\n",
    "svc_model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "Y_pred = svc_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"=== Linear SVC ===\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d0af8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== K-Nearest Neighbors (KNN) ===\n",
      "Accuracy: 0.76\n",
      "Precision: 0.77\n",
      "Recall: 0.76\n",
      "F1-Score: 0.76\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75      3701\n",
      "           1       0.74      0.83      0.78      3799\n",
      "\n",
      "    accuracy                           0.76      7500\n",
      "   macro avg       0.77      0.76      0.76      7500\n",
      "weighted avg       0.77      0.76      0.76      7500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2591 1110]\n",
      " [ 663 3136]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "Y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"=== K-Nearest Neighbors (KNN) ===\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d25a2158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decision Tree Classifier ===\n",
      "Accuracy: 0.71\n",
      "Precision: 0.71\n",
      "Recall: 0.71\n",
      "F1-Score: 0.71\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71      3701\n",
      "           1       0.72      0.71      0.71      3799\n",
      "\n",
      "    accuracy                           0.71      7500\n",
      "   macro avg       0.71      0.71      0.71      7500\n",
      "weighted avg       0.71      0.71      0.71      7500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2621 1080]\n",
      " [1087 2712]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "Y_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"=== Decision Tree Classifier ===\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3754292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(log_model, 'logistic_regression_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e36377b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"9999_0\"</td>\n",
       "      <td>\"Watching Time Chasers, it obvious that it was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"45057_0\"</td>\n",
       "      <td>\"I saw this film about 20 years ago and rememb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"15561_0\"</td>\n",
       "      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7161_0\"</td>\n",
       "      <td>\"I went to see this film with a great deal of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"43971_0\"</td>\n",
       "      <td>\"Yes, I agree with everyone on this site this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>\"18984_0\"</td>\n",
       "      <td>\"The original Man Eater by Joe D'Amato is some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>\"16433_0\"</td>\n",
       "      <td>\"When Home Box Office was in it's early days m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>\"16006_0\"</td>\n",
       "      <td>\"Griffin Dunne was born into a cultural family...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>\"40155_0\"</td>\n",
       "      <td>\"Not a bad story, but the low budget rears its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>\"35270_0\"</td>\n",
       "      <td>\"This not-very-good mummy-alien flick does fea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                             review\n",
       "0       \"9999_0\"  \"Watching Time Chasers, it obvious that it was...\n",
       "1      \"45057_0\"  \"I saw this film about 20 years ago and rememb...\n",
       "2      \"15561_0\"  \"Minor Spoilers<br /><br />In New York, Joan B...\n",
       "3       \"7161_0\"  \"I went to see this film with a great deal of ...\n",
       "4      \"43971_0\"  \"Yes, I agree with everyone on this site this ...\n",
       "...          ...                                                ...\n",
       "49995  \"18984_0\"  \"The original Man Eater by Joe D'Amato is some...\n",
       "49996  \"16433_0\"  \"When Home Box Office was in it's early days m...\n",
       "49997  \"16006_0\"  \"Griffin Dunne was born into a cultural family...\n",
       "49998  \"40155_0\"  \"Not a bad story, but the low budget rears its...\n",
       "49999  \"35270_0\"  \"This not-very-good mummy-alien flick does fea...\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\razas\\Downloads\\TechnoHacks Internship\\Technohack Machine Learning\\Movie review classification\\unlabeledTrainData.tsv\\unlabeledTrainData.tsv\"\n",
    "df2 = pd.read_csv(file_path, sep=\"\\t\", quoting=3)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab303761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review         id  \\\n",
      "0  \"Watching Time Chasers, it obvious that it was...   \"9999_0\"   \n",
      "1  \"I saw this film about 20 years ago and rememb...  \"45057_0\"   \n",
      "2  \"Minor Spoilers<br /><br />In New York, Joan B...  \"15561_0\"   \n",
      "3  \"I went to see this film with a great deal of ...   \"7161_0\"   \n",
      "4  \"Yes, I agree with everyone on this site this ...  \"43971_0\"   \n",
      "\n",
      "  predicted_label  \n",
      "0        Negative  \n",
      "1        Negative  \n",
      "2        Negative  \n",
      "3        Negative  \n",
      "4        Negative  \n"
     ]
    }
   ],
   "source": [
    "# Preprocess df2 reviews\n",
    "df2['cleaned_review'] = df2['review'].apply(preprocess_text)\n",
    "\n",
    "# Vectorize using the trained vectorizer (same as used on X_train)\n",
    "df2_vectorized = vectorizer.transform(df2['cleaned_review'])\n",
    "\n",
    "# Predict using the trained model\n",
    "df2['predicted_sentiment'] = log_model.predict(df2_vectorized)\n",
    "\n",
    "# Convert numerical prediction to label\n",
    "df2['predicted_label'] = df2['predicted_sentiment'].apply(lambda x: 'Positive' if x == 1 else 'Negative')\n",
    "\n",
    "# View result\n",
    "print(df2[['review', 'id','predicted_label']].head())\n",
    "\n",
    "# Optional: Save predictions to CSV\n",
    "df2.to_csv('df2_sentiment_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c58c104d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>\"Naturally in a film who's main themes are of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>\"This movie is a disaster within a disaster fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>\"All in all, this is a movie for kids. We saw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>\"Afraid of the Dark left me with the impressio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             review\n",
       "0          id                                             review\n",
       "1  \"12311_10\"  \"Naturally in a film who's main themes are of ...\n",
       "2    \"8348_2\"  \"This movie is a disaster within a disaster fi...\n",
       "3    \"5828_4\"  \"All in all, this is a movie for kids. We saw ...\n",
       "4    \"7186_2\"  \"Afraid of the Dark left me with the impressio..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\razas\\Downloads\\TechnoHacks Internship\\Technohack Machine Learning\\Movie review classification\\testData.tsv\\testData.tsv\"\n",
    "\n",
    "# Read the TSV file (without headers)\n",
    "df3 = pd.read_csv(file_path, sep='\\t', quoting=3, header=None, names=[\"id\", \"review\"])\n",
    "\n",
    "# Preview the DataFrame\n",
    "df3.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb772ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(\"testdata.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0a2f0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review          id  \\\n",
      "0                                             review          id   \n",
      "1  \"Naturally in a film who's main themes are of ...  \"12311_10\"   \n",
      "2  \"This movie is a disaster within a disaster fi...    \"8348_2\"   \n",
      "3  \"All in all, this is a movie for kids. We saw ...    \"5828_4\"   \n",
      "4  \"Afraid of the Dark left me with the impressio...    \"7186_2\"   \n",
      "\n",
      "  predicted_label  \n",
      "0        Negative  \n",
      "1        Positive  \n",
      "2        Negative  \n",
      "3        Positive  \n",
      "4        Positive  \n"
     ]
    }
   ],
   "source": [
    "# Preprocess df2 reviews\n",
    "df3['cleaned_review'] = df3['review'].apply(preprocess_text)\n",
    "\n",
    "# Vectorize using the trained vectorizer (same as used on X_train)\n",
    "df3_vectorized = vectorizer.transform(df3['cleaned_review'])\n",
    "\n",
    "# Predict using the trained model\n",
    "df3['predicted_sentiment'] = log_model.predict(df3_vectorized)\n",
    "\n",
    "# Convert numerical prediction to label\n",
    "df3['predicted_label'] = df3['predicted_sentiment'].apply(lambda x: 'Positive' if x == 1 else 'Negative')\n",
    "\n",
    "# View result\n",
    "print(df3[['review', 'id','predicted_label']].head())\n",
    "\n",
    "# Optional: Save predictions to CSV\n",
    "df3.to_csv('df3_sentiment_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e540e3",
   "metadata": {},
   "source": [
    "# project ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba8201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
